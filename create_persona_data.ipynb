{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import yaml\n",
    "\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    config = yaml.safe_load(open('config.yaml'))\n",
    "\n",
    "    return config\n",
    "\n",
    "def download_content(url, file_path):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',\n",
    "        'Accept-Language': 'en-US,en;q=0.5'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response == 200:\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "\n",
    "def extract_all(file_path):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    with ZipFile(file_path, 'r') as zf:\n",
    "        zf.extractall()\n",
    "\n",
    "def load_file(file_path, **kwargs):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    _, extsn = os.path.splitext(file_path)\n",
    "\n",
    "    if extsn == '.csv':\n",
    "        df = pd.read_csv(file_path, **kwargs)\n",
    "    elif extsn == '.xlsx':\n",
    "        df = pd.read_excel(file_path, **kwargs)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def download_ce_zip_file():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    config = load_config()\n",
    "\n",
    "    url = os.path.join(\n",
    "        config['BASE_URL'],\n",
    "        config['SURVEY_SOURCE'] + config['COLLECTION_QUARTER'][2:4] + '.zip'\n",
    "    )\n",
    "\n",
    "    file_path = os.path.join(\n",
    "        config['DATA_DIRECTORY'],\n",
    "        config['SURVEY_SOURCE'] + config['COLLECTION_QUARTER'][2:4] + '.zip'\n",
    "    )\n",
    "\n",
    "    download_content(url=url, file_path=file_path)\n",
    "    extract_all(file_path=file_path)\n",
    "\n",
    "def load_ce_data():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    config = load_config()\n",
    "\n",
    "    file_path = os.path.join(\n",
    "        config['DATA_DIRECTORY'],\n",
    "        config['SURVEY_SOURCE'].lower() + config['COLLECTION_QUARTER'][2:4],\n",
    "        config['DATASET_BASE_NAME'] + config['COLLECTION_QUARTER'][2:] + config['DATASET_EXTENSION']\n",
    "    )\n",
    "\n",
    "    data = load_file(file_path=file_path)\n",
    "\n",
    "    if all([col in data.columns for col in config['DATASET_COLUMNS']]):\n",
    "        data = data[config['DATASET_COLUMNS']]\n",
    "\n",
    "    return data\n",
    "\n",
    "def load_ce_data_dict(sheet_name):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Load config.\n",
    "    config = load_config()\n",
    "\n",
    "    # Set file path for data dictionary.\n",
    "    file_path = os.path.join(\n",
    "        config['DATA_DIRECTORY'],\n",
    "        config['DATA_DICTIONARY']\n",
    "    )\n",
    "\n",
    "    # Load file.\n",
    "    data_dict = load_file(file_path=file_path, sheet_name=sheet_name)\n",
    "\n",
    "    # Edit for data inconsistency between data files and data dictionary\n",
    "    # files.\n",
    "    if config['SURVEY_SOURCE'] == 'intrvw':\n",
    "        survey_source = 'INTERVIEW'\n",
    "    else:\n",
    "        survey_source = config['SURVEY_SOURCE']\n",
    "\n",
    "    # Subset the data diciontary to the survey source and dataset file\n",
    "    # name.\n",
    "    data_dict = data_dict.loc[\n",
    "        (data_dict['Survey'] == survey_source)\n",
    "        & (data_dict['File'] == config['DATASET_BASE_NAME'].upper())\n",
    "        & (data_dict['Last quarter'].isna())\n",
    "    ]\n",
    "\n",
    "    # If variables descriptions tab, then keep variable name and\n",
    "    # description. If looking for descriptions of the values, then\n",
    "    # keep variable, value, and the value's description.\n",
    "    if sheet_name == 'Variables':\n",
    "        data_dict = data_dict.loc[\n",
    "            data_dict['Variable Name'].isin(config['DATASET_COLUMNS']),\n",
    "            ['Variable Name', 'Variable description']\n",
    "        ]\n",
    "    elif sheet_name == 'Codes ':\n",
    "        data_dict = data_dict.loc[\n",
    "            data_dict['Variable '].isin(config['DATASET_COLUMNS']),\n",
    "            ['Variable ', 'Code value', 'Code description']\n",
    "        ]\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "def write_data_list(file_name, data_list):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Load config.\n",
    "    config = load_config()\n",
    "\n",
    "    # Create file path for writing data.\n",
    "    file_path = os.path.join(config['DATA_DIRECTORY'], file_name)\n",
    "\n",
    "    # For each data frame in the list of data frames, write to a sheet\n",
    "    # on the workbook.\n",
    "    with pd.ExcelWriter(file_path, engine='xlsxwriter') as writer:\n",
    "        for data, sheet_name in data_list:\n",
    "            data.to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL DOWNLOAD REQUIRED.\n",
    "# \n",
    "# REQUEST IS RETURNING RESPONSE 403. NOT SURE WHY BLS IS STRICT ABOUT\n",
    "# DOWNLOADING PUMD PROGRAMTICALLY.\n",
    "# \n",
    "# TODO: TRY CHANGING USER AGENT HEADER; SELENIUM WEB DRIVER; USING API\n",
    "# (NOTORIOUS).\n",
    "\n",
    "# download_ce_zip_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4751, 26)\n",
      "(26, 2)\n",
      "(109, 3)\n"
     ]
    }
   ],
   "source": [
    "data = load_ce_data()\n",
    "print(data.shape)\n",
    "\n",
    "data_dict_vars = load_ce_data_dict(sheet_name='Variables')\n",
    "print(data_dict_vars.shape)\n",
    "\n",
    "data_dict_codes = load_ce_data_dict(sheet_name='Codes ')\n",
    "print(data_dict_codes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'ce_survey_data.xlsx'\n",
    "\n",
    "df_list = [\n",
    "    (data, 'data'),\n",
    "    (data_dict_vars, 'data_var_desc'),\n",
    "    (data_dict_codes, 'data_code_desc')\n",
    "]\n",
    "\n",
    "write_data_list(file_name=file_name, data_list=df_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
